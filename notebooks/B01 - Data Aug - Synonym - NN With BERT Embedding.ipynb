{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import sklearn\n",
    "import nltk\n",
    "import os\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../data/input/imperatives/ground_truth/'\n",
    "OUTPUT_DIR = '../data/'\n",
    "MODEL_DIR = '../models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_file = os.path.join(INPUT_DIR, 'imperatives_binary_data.csv')\n",
    "df_data_raw = pd.read_csv(ip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Find a sturdy piece of cardboard in the form o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stand up for yourself</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fix out priorities together in a meeting  a co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Make one last snowball for the penguin's head</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Look for the internet venue you will use for y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>it's a Finnish documentary but it has all thes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>yeah  because you took time when you had your ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>oh  come on  you're kidding  right.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>You see.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>Do you think we need to do more.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2324 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Find a sturdy piece of cardboard in the form o...      1\n",
       "1                                 Stand up for yourself      1\n",
       "2     Fix out priorities together in a meeting  a co...      1\n",
       "3         Make one last snowball for the penguin's head      1\n",
       "4     Look for the internet venue you will use for y...      1\n",
       "...                                                 ...    ...\n",
       "2319  it's a Finnish documentary but it has all thes...      0\n",
       "2320  yeah  because you took time when you had your ...      0\n",
       "2321                oh  come on  you're kidding  right.      0\n",
       "2322                                           You see.      0\n",
       "2323                   Do you think we need to do more.      0\n",
       "\n",
       "[2324 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_data_raw['text']\n",
    "label = df_data_raw['label']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, label_train, label_test = train_test_split(data, label, test_size=0.20, \n",
    "                                                                  random_state=0, stratify=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_raw_train = pd.DataFrame(list(zip(data_train, label_train)), columns=['text', 'label'])\n",
    "df_data_raw_test = pd.DataFrame(list(zip(data_test, label_test)), columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1859, 2) (465, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_data_raw_train.shape, df_data_raw_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_synonyms(word):\n",
    "    synonyms = []\n",
    "    # antonyms = []\n",
    "\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.append(l.name())\n",
    "                \n",
    "    return list(set(synonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def replace_synonym(sentence, word):\n",
    "    \n",
    "    augmented_sentences = []\n",
    "    augmented_sentences.append(sentence)\n",
    "    \n",
    "    sentence_words = sentence.split(' ')\n",
    "    \n",
    "    if word in sentence_words:\n",
    "        \n",
    "        synonyms = get_synonyms(word)\n",
    "    \n",
    "        for synonym in synonyms:\n",
    "            reg_ex = r'\\b'+word+r'\\b'\n",
    "            new_setence = re.sub(reg_ex, synonym, sentence)\n",
    "        \n",
    "            augmented_sentences.append(new_setence)\n",
    "        \n",
    "    return augmented_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_augmentation(sentence):\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    for word in words:\n",
    "        # print('---------------------\\n', word)\n",
    "        new_sentences = replace_synonym(sentence, word)\n",
    "        # print(new_sentences)\n",
    "        sentences.extend(new_sentences)\n",
    "        \n",
    "    return list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_augmentation_withoutstopwords(sentence):\n",
    "    \n",
    "    sentences = []\n",
    "    \n",
    "    words = sentence.split(' ')\n",
    "    \n",
    "    for word in words:\n",
    "        # print('---------------------\\n', word)\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_sentences = replace_synonym(sentence, word)\n",
    "            # print(new_sentences)\n",
    "            sentences.extend(new_sentences)\n",
    "        \n",
    "    return list(set(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imperative_train = df_data_raw_train.loc[df_data_raw_train['label'] == 1]\n",
    "df_nonimperative_train = df_data_raw_train.loc[df_data_raw_train['label'] == 0]\n",
    "\n",
    "# df_imperative_test = df_data_raw_test.loc[df_data_raw_test['label'] == 1]\n",
    "# df_nonimperative_test = df_data_raw_test.loc[df_data_raw_test['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmented_dataframe(sentence, label):\n",
    "    \n",
    "    augmented_sentences = synonym_augmentation_withoutstopwords(sentence)\n",
    "    labels = [label] * len(augmented_sentences)\n",
    "    \n",
    "    df = pd.DataFrame(list(zip(augmented_sentences, labels)), columns=['text', 'label'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_imperative_train = pd.DataFrame(columns=['text', 'label'])\n",
    "for index, row in df_imperative_train.iterrows():\n",
    "    \n",
    "    sentence = row['text']\n",
    "    label = row['label']\n",
    "    \n",
    "    df = get_augmented_dataframe(sentence, label)\n",
    "    \n",
    "    df_aug_imperative_train = pd.concat([df_aug_imperative_train, df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 53760 entries, 0 to 171\n",
      "Data columns (total 2 columns):\n",
      "text     53760 non-null object\n",
      "label    53760 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aug_imperative_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 53760})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_aug_imperative_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learn to enjoy cook from scratch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read to enjoy cooking from scratch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>discover to enjoy cooking from scratch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Learn to enjoy cooking from incision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>con to enjoy cooking from scratch</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text label\n",
       "0        Learn to enjoy cook from scratch     1\n",
       "1      read to enjoy cooking from scratch     1\n",
       "2  discover to enjoy cooking from scratch     1\n",
       "3    Learn to enjoy cooking from incision     1\n",
       "4       con to enjoy cooking from scratch     1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug_imperative_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug_nonimperative_train = pd.DataFrame(columns=['text', 'label'])\n",
    "for index, row in df_nonimperative_train.iterrows():\n",
    "    \n",
    "    sentence = row['text']\n",
    "    label = row['label']\n",
    "    \n",
    "    df = get_augmented_dataframe(sentence, label)\n",
    "    \n",
    "    df_aug_nonimperative_train = pd.concat([df_aug_nonimperative_train, df], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 46362})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_aug_nonimperative_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46362 entries, 0 to 442\n",
      "Data columns (total 2 columns):\n",
      "text     46362 non-null object\n",
      "label    46362 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_aug_nonimperative_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gopher snakes in Arizona are not poisonous  bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gopher snakes in Arizona are not poisonous  bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gopher snakes in Arizona are not poisonous  bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gopher snakes in Arizona are not vicious  but ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gopher snakes in Arizona are not poisonous  bu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  Gopher snakes in Arizona are not poisonous  bu...     0\n",
       "1  Gopher snakes in Arizona are not poisonous  bu...     0\n",
       "2  Gopher snakes in Arizona are not poisonous  bu...     0\n",
       "3  Gopher snakes in Arizona are not vicious  but ...     0\n",
       "4  Gopher snakes in Arizona are not poisonous  bu...     0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aug_nonimperative_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.concat([df_aug_nonimperative_train, df_aug_imperative_train], axis=0, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_file = os.path.join(INPUT_DIR, 'imperatives_binary_synonym_aug_train.csv')\n",
    "df_data_train.to_csv(ip_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 46362, 1: 53760})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(df_data_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = df_data_train['text']\n",
    "label_train = df_data_train['label']\n",
    "\n",
    "data_test = df_data_raw_test['text']\n",
    "label_test = df_data_raw_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data split Counter({1: 53760, 0: 46362})\n",
      "Testing Data split Counter({1: 234, 0: 231})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print('Training Data split', Counter(label_train))\n",
    "print('Testing Data split', Counter(label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_train = pd.DataFrame(list(zip(data_train, label_train)), columns=['text', 'label'])\n",
    "df_data_test = pd.DataFrame(list(zip(data_test, label_test)), columns=['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and my first paper I got a C on and I'd knew t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shut the door</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I took some summer courses.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You better be quit!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  and my first paper I got a C on and I'd knew t...      0\n",
       "1                                      Shut the door      1\n",
       "2                        I took some summer courses.      0\n",
       "3                                You better be quit!      1\n",
       "4                                                So.      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # print(text, end ='')\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W',' ', text)\n",
    "    text = re.sub(' \\d+', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "        \n",
    "    words = text.split(' ')\n",
    "    words = [w.strip() for w in words]\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    text = text.strip()\n",
    "        \n",
    "    # print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df_data):\n",
    "    df_data['processed_text'] = df_data['text'].apply(lambda x: preprocess_text(x))\n",
    "    df_data.drop(df_data[df_data['processed_text'] == ''].index, inplace=True)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train before cleaning (100122, 2)\n",
      "Train after cleaning (100122, 3)\n",
      "Test before cleaning (465, 2)\n",
      "Test after cleaning (465, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess train & test data frame\n",
    "print('Train before cleaning', df_data_train.shape)\n",
    "df_data_train = preprocess_df(df_data_train)\n",
    "print('Train after cleaning', df_data_train.shape)\n",
    "\n",
    "\n",
    "print('Test before cleaning', df_data_test.shape)\n",
    "df_data_test = preprocess_df(df_data_test)\n",
    "print('Test after cleaning', df_data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>and my first paper I got a C on and I'd knew t...</td>\n",
       "      <td>0</td>\n",
       "      <td>and my first paper i got a c on and i d knew t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Shut the door</td>\n",
       "      <td>1</td>\n",
       "      <td>shut the door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I took some summer courses.</td>\n",
       "      <td>0</td>\n",
       "      <td>i took some summer courses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You better be quit!</td>\n",
       "      <td>1</td>\n",
       "      <td>you better be quit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>So.</td>\n",
       "      <td>0</td>\n",
       "      <td>so</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  and my first paper I got a C on and I'd knew t...      0   \n",
       "1                                      Shut the door      1   \n",
       "2                        I took some summer courses.      0   \n",
       "3                                You better be quit!      1   \n",
       "4                                                So.      0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  and my first paper i got a c on and i d knew t...  \n",
       "1                                      shut the door  \n",
       "2                         i took some summer courses  \n",
       "3                                 you better be quit  \n",
       "4                                                 so  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Corpus using only train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length  100122\n"
     ]
    }
   ],
   "source": [
    "corpus = df_data_train['text'].values\n",
    "print('Corpus Length ', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Use Bag of Words Vectorizer for encoding`\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data train: (100122, 14035)\n"
     ]
    }
   ],
   "source": [
    "data_train = vectorizer.transform(df_data_train['text'])\n",
    "print('Shape of the data train:',data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = np.array(df_data_train['label'])\n",
    "label_train = label_train.reshape((len(label_train), 1))\n",
    "label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data train: (465, 14035)\n"
     ]
    }
   ],
   "source": [
    "data_test = vectorizer.transform(df_data_test['text'])\n",
    "print('Shape of the data train:',data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = np.array(df_data_test['label'])\n",
    "label_test = label_test.reshape((len(label_test), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with poly (3) kernel - with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talat/anaconda3/envs/sentgen/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Run Logistic Regression\n",
    "estimator = SVC(kernel='poly', degree=3)\n",
    "estimator.fit(data_train, label_train)\n",
    "predictions = estimator.predict(data_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9510519570460824\n",
      "Test Accuracy 0.632258064516129\n",
      "F1 macro Score:  0.5920403880785392\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.32      0.46       231\n",
      "           1       0.58      0.94      0.72       234\n",
      "\n",
      "    accuracy                           0.63       465\n",
      "   macro avg       0.71      0.63      0.59       465\n",
      "weighted avg       0.71      0.63      0.59       465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Accuracy Measure\n",
    "print('Train Accuracy', estimator.score(data_train, label_train))\n",
    "print('Test Accuracy', estimator.score(data_test, label_test))\n",
    "\n",
    "# F1\n",
    "f1_measure = f1_score(label_test, predictions, average='macro')\n",
    "print('F1 macro Score: ', f1_measure)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = MODEL_DIR + 'svm/' + 'model_svm_poly3_synonym_aug_withstopwords.pkl'\n",
    "with open(model_file, 'wb') as f_op:\n",
    "    pkl.dump(estimator, f_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM with linear kernel - with stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/talat/anaconda3/envs/sentgen/lib/python3.5/site-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "estimator = SVC(kernel='linear')\n",
    "estimator.fit(data_train, label_train)\n",
    "predictions = estimator.predict(data_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9971035336888996\n",
      "Test Accuracy 0.789247311827957\n",
      "F1 macro Score:  0.7883064516129032\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.73      0.77       231\n",
      "           1       0.76      0.85      0.80       234\n",
      "\n",
      "    accuracy                           0.79       465\n",
      "   macro avg       0.79      0.79      0.79       465\n",
      "weighted avg       0.79      0.79      0.79       465\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Accuracy Measure\n",
    "print('Train Accuracy', estimator.score(data_train, label_train))\n",
    "print('Test Accuracy', estimator.score(data_test, label_test))\n",
    "\n",
    "# F1\n",
    "f1_measure = f1_score(label_test, predictions, average='macro')\n",
    "print('F1 macro Score: ', f1_measure)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_file = MODEL_DIR + 'svm/' + 'model_svm_linear_synonym_aug_withstopwords.pkl'\n",
    "with open(model_file, 'wb') as f_op:\n",
    "    pkl.dump(estimator, f_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = data_train.shape[1]  # Number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140360    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 140,371\n",
      "Trainable params: 140,371\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Dense(10, input_dim=input_dim, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10013/10013 [==============================] - 8s 775us/step - loss: 0.0029 - accuracy: 0.9991 - val_accuracy: 0.8172 - val_loss: 2.2232\n",
      "Epoch 2/100\n",
      "10013/10013 [==============================] - 8s 783us/step - loss: 0.0022 - accuracy: 0.9993 - val_accuracy: 0.8215 - val_loss: 2.3012\n",
      "Epoch 3/100\n",
      "10013/10013 [==============================] - 8s 775us/step - loss: 0.0017 - accuracy: 0.9994 - val_accuracy: 0.8043 - val_loss: 2.4633\n",
      "Epoch 4/100\n",
      "10013/10013 [==============================] - 7s 738us/step - loss: 0.0014 - accuracy: 0.9995 - val_accuracy: 0.8172 - val_loss: 2.6541\n",
      "Epoch 5/100\n",
      "10013/10013 [==============================] - 8s 796us/step - loss: 0.0012 - accuracy: 0.9996 - val_accuracy: 0.8043 - val_loss: 2.6704\n",
      "Epoch 6/100\n",
      "10013/10013 [==============================] - 8s 835us/step - loss: 9.2613e-04 - accuracy: 0.9996 - val_accuracy: 0.8108 - val_loss: 2.8776\n",
      "Epoch 7/100\n",
      "10013/10013 [==============================] - 8s 780us/step - loss: 8.1199e-04 - accuracy: 0.9997 - val_accuracy: 0.8151 - val_loss: 3.0114\n",
      "Epoch 8/100\n",
      "10013/10013 [==============================] - 8s 788us/step - loss: 6.3730e-04 - accuracy: 0.9998 - val_accuracy: 0.7957 - val_loss: 3.1774\n",
      "Epoch 9/100\n",
      "10013/10013 [==============================] - 10s 979us/step - loss: 5.5288e-04 - accuracy: 0.9998 - val_accuracy: 0.7978 - val_loss: 3.3862\n",
      "Epoch 10/100\n",
      "10013/10013 [==============================] - 12s 1ms/step - loss: 5.2479e-04 - accuracy: 0.9998 - val_accuracy: 0.8043 - val_loss: 3.5003\n",
      "Epoch 11/100\n",
      "10013/10013 [==============================] - 15s 1ms/step - loss: 4.0677e-04 - accuracy: 0.9998 - val_accuracy: 0.8022 - val_loss: 3.6402\n",
      "Epoch 12/100\n",
      "10013/10013 [==============================] - 12s 1ms/step - loss: 3.4998e-04 - accuracy: 0.9998 - val_accuracy: 0.8022 - val_loss: 3.8264\n",
      "Epoch 13/100\n",
      "10013/10013 [==============================] - 10s 956us/step - loss: 3.3697e-04 - accuracy: 0.9999 - val_accuracy: 0.7935 - val_loss: 3.9674\n",
      "Epoch 14/100\n",
      "10013/10013 [==============================] - 9s 925us/step - loss: 2.8800e-04 - accuracy: 0.9999 - val_accuracy: 0.7914 - val_loss: 4.1150\n",
      "Epoch 15/100\n",
      "10013/10013 [==============================] - 10s 997us/step - loss: 2.6124e-04 - accuracy: 0.9999 - val_accuracy: 0.7892 - val_loss: 4.2415\n",
      "Epoch 16/100\n",
      "10013/10013 [==============================] - 11s 1ms/step - loss: 2.3642e-04 - accuracy: 0.9999 - val_accuracy: 0.7978 - val_loss: 4.2987\n",
      "Epoch 17/100\n",
      "10013/10013 [==============================] - 11s 1ms/step - loss: 2.1180e-04 - accuracy: 0.9999 - val_accuracy: 0.7935 - val_loss: 4.4416\n",
      "Epoch 18/100\n",
      "10013/10013 [==============================] - 10s 1ms/step - loss: 2.0704e-04 - accuracy: 0.9999 - val_accuracy: 0.7957 - val_loss: 4.5380\n",
      "Epoch 19/100\n",
      "10013/10013 [==============================] - 12s 1ms/step - loss: 1.6615e-04 - accuracy: 0.9999 - val_accuracy: 0.7957 - val_loss: 4.6669\n",
      "Epoch 20/100\n",
      "10013/10013 [==============================] - 13s 1ms/step - loss: 1.7668e-04 - accuracy: 0.9999 - val_accuracy: 0.7914 - val_loss: 4.7946\n",
      "Epoch 21/100\n",
      " 8700/10013 [=========================>....] - ETA: 2s - loss: 1.3543e-04 - accuracy: 0.9999"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_train, label_train,\n",
    "                    epochs=100,\n",
    "                    verbose=True, \n",
    "                    validation_data=(data_test, label_test),\n",
    "                    batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(data_train, label_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(data_test, label_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentgen",
   "language": "python",
   "name": "sentgen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
