{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../data/input/'\n",
    "OUTPUT_DIR = '../data/output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the input train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_input(file_path, debug=False):\n",
    "\n",
    "    df_data = pd.DataFrame(columns=['label', 'sentence'])\n",
    "    \n",
    "    with open(file_path, 'r') as fp:\n",
    "        line = fp.readline()\n",
    "        index = 0\n",
    "        while line:\n",
    "            sections = line.split('\\t')\n",
    "            label = np.int16(sections[0].strip())\n",
    "            sentence = str(sections[1].strip())\n",
    "\n",
    "            if label < 3:\n",
    "                df_data.loc[index] = [label, sentence]\n",
    "                index += 1\n",
    "\n",
    "            line = fp.readline()\n",
    "\n",
    "    if debug:    \n",
    "        print(df_data.head())\n",
    "        print(df_data.describe())\n",
    "        print(df_data.info())\n",
    "        labels = np.unique(df_data['label'])\n",
    "        print(labels)\n",
    "\n",
    "        label_counter = Counter(df_data['label'])\n",
    "        print(label_counter)\n",
    "        \n",
    "    \n",
    "    df_data['label'] = df_data['label'].astype(np.uint8)\n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                           sentence\n",
      "0     0  A cockroach will live nine days without itâ€™s h...\n",
      "1     0  More people are killed each year from bees tha...\n",
      "2     0  Well i-, well it seemed to make sense since I ...\n",
      "3     0                 So, I have none left what so ever.\n",
      "4     0  You have you have a lot of younger brothers an...\n",
      "        label sentence\n",
      "count    1388     1388\n",
      "unique      3     1382\n",
      "top         0    yeah.\n",
      "freq      664        2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1388 entries, 0 to 1387\n",
      "Data columns (total 2 columns):\n",
      "label       1388 non-null object\n",
      "sentence    1388 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 32.5+ KB\n",
      "None\n",
      "[0 1 2]\n",
      "Counter({0: 664, 2: 381, 1: 343})\n"
     ]
    }
   ],
   "source": [
    "train_file = INPUT_DIR + 'trn_data'\n",
    "df_data_train = read_input(train_file, True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                           sentence\n",
      "0     0  Like if she'll ask me where are my crayons whe...\n",
      "1     0         Ketchup was sold in the 1830s as medicine.\n",
      "2     0                                 I need some water.\n",
      "3     0                                         yeah yeah.\n",
      "4     0  kind of telling him that, you know, from my re...\n",
      "        label sentence\n",
      "count     232      232\n",
      "unique      3      231\n",
      "top         2     Why.\n",
      "freq       85        2\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 232 entries, 0 to 231\n",
      "Data columns (total 2 columns):\n",
      "label       232 non-null object\n",
      "sentence    232 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 5.4+ KB\n",
      "None\n",
      "[0 1 2]\n",
      "Counter({2: 85, 1: 76, 0: 71})\n"
     ]
    }
   ],
   "source": [
    "test_file = INPUT_DIR + 'tst_data'\n",
    "df_data_test = read_input(test_file, True).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Info: \n",
    "    \n",
    "1. 0 --> \n",
    "2. 1 --> \n",
    "3. 2 --> \n",
    "4. 3 --> NA - Shouldn't be included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    "    # print(text, end ='')\n",
    "    \n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\W',' ', text)\n",
    "    text = re.sub(' \\d+', ' ', text)\n",
    "    text = re.sub(r'\\s+',' ', text)\n",
    "        \n",
    "    words = text.split(' ')\n",
    "    words = [w.strip() for w in words if w not in stopwords.words('english')]\n",
    "    \n",
    "    text = ' '.join(words)\n",
    "    text = text.strip()\n",
    "        \n",
    "    # print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_df(df_data):\n",
    "    df_data['proc_sentence'] = df_data['sentence'].apply(lambda x: preprocess_text(x))\n",
    "    df_data.drop(df_data[df_data['proc_sentence'] == ''].index, inplace=True)\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train before cleaning (1388, 2)\n",
      "Train after cleaning (1358, 3)\n",
      "Test before cleaning (232, 2)\n",
      "Test after cleaning (227, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess train & test data frame\n",
    "print('Train before cleaning', df_data_train.shape)\n",
    "df_data_train = preprocess_df(df_data_train)\n",
    "print('Train after cleaning', df_data_train.shape)\n",
    "\n",
    "\n",
    "print('Test before cleaning', df_data_test.shape)\n",
    "df_data_test = preprocess_df(df_data_test)\n",
    "print('Test after cleaning', df_data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Corpus using only train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Length  1358\n"
     ]
    }
   ],
   "source": [
    "corpus = df_data_train['sentence'].values\n",
    "print('Corpus Length ', len(corpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "## Use Bag of Words Vectorizer for encoding`\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data train: (1358, 2766)\n"
     ]
    }
   ],
   "source": [
    "data_train = vectorizer.transform(df_data_train['sentence'])\n",
    "print('Shape of the data train:',data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_train = np.array(df_data_train['label'])\n",
    "label_train = label_train.reshape((len(label_train), 1))\n",
    "label_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data train: (227, 2766)\n"
     ]
    }
   ],
   "source": [
    "data_test = vectorizer.transform(df_data_test['sentence'])\n",
    "print('Shape of the data train:',data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_test = np.array(df_data_test['label'])\n",
    "label_test = label_test.reshape((len(label_test), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 2, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 1, 1, 1, 2, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 2, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 1, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 2, 1, 2, 0, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 0, 1, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2,\n",
       "       0, 2, 2, 0, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
       "       2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0,\n",
       "       2, 2, 1, 2, 0, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Run Logistic Regression\n",
    "log_regr = LogisticRegression()\n",
    "log_regr.fit(data_train, label_train)\n",
    "predictions = log_regr.predict(data_test)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy 0.9742268041237113\n",
      "Test Accuracy 0.6784140969162996\n",
      "F1 macro Score:  0.6710357243800309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.72      0.63        71\n",
      "           1       0.71      0.52      0.60        71\n",
      "           2       0.80      0.78      0.79        85\n",
      "\n",
      "    accuracy                           0.68       227\n",
      "   macro avg       0.69      0.67      0.67       227\n",
      "weighted avg       0.69      0.68      0.68       227\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "## Accuracy Measure\n",
    "print('Train Accuracy', log_regr.score(data_train, label_train))\n",
    "print('Test Accuracy', log_regr.score(data_test, label_test))\n",
    "\n",
    "# F1\n",
    "f1_measure = f1_score(label_test, predictions, average='macro')\n",
    "print('F1 macro Score: ', f1_measure)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(label_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechact",
   "language": "python",
   "name": "speechact"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
